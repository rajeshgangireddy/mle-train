data:
  path: "demo_space/data/datatraining.txt"
  ignore_columns: []
  index_column: 0

random_seed: 42

feature_engineering:
  datetime_features: ["date"]
  datetime_format: "%Y-%m-%d %H:%M:%S"
  categorical_features: ["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]
  target: "Occupancy"


models:
  destination: "demo_space/save_models"
  type: "XGBClassifier"
  parameters:
    n_estimators: [10, 50, 100, 200]
    max_depth: [3, 5, 7, 9]
    learning_rate: [0.01, 0.1, 0.3]

  # If the  Data Scientist wants to try a different model, they can add it here.
  # The code will automatically train the model and save the best one.
#  - type: "RandomForestClassifier"
#    hyperparameters:
#      n_estimators: [50, 100, 200]
#      max_depth: [5, 10, 15]
#      min_samples_split: [2, 5, 10]


training:
  hyperparameter_optimisation:
    n_iter: 10                          # Number of iterations for the hyperparameter search
    scoring: "roc_auc"                  # Scoring metric for hyperparameter optimization
    n_jobs: 2                           # Number of jobs to run in parallel, -1 means using all processors
    cv: 8                               # Number of folds in cross-validation
  test_size: 0.2
